{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d147a727",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f184a798",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn # All the building blocks for neural networks\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55702d06",
   "metadata": {},
   "source": [
    "### Setup device-agnostic code (running the code on any available accelerator):\n",
    "\n",
    "PyTorch is capable of running on both GPU or CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b30448",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch.cuda.device_count()\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893c51e0",
   "metadata": {},
   "source": [
    "### Scalar & Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfff794a",
   "metadata": {},
   "outputs": [],
   "source": [
    "scalar = torch.tensor(5)\n",
    "scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b7ad77",
   "metadata": {},
   "outputs": [],
   "source": [
    "scalar.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9e31d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = torch.tensor([1,3])\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2c7e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9175b51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13510354",
   "metadata": {},
   "source": [
    "### Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6404d07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAT = torch.tensor([[1, 2],[3, 3], [3,4]])\n",
    "MAT.ndim\n",
    "MAT.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6784813",
   "metadata": {},
   "source": [
    "### Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8631a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEN = torch.tensor([[[1,2,3],\n",
    "                     [2,3,3],\n",
    "                     [1,1,1],\n",
    "                     [10,10,10]],\n",
    "                    [[2,2,2],\n",
    "                     [1,1,1],\n",
    "                     [10.,11,11],\n",
    "                     [13,13,13]]])\n",
    "TEN.ndim\n",
    "TEN.size\n",
    "TEN.shape\n",
    "TEN.dim\n",
    "TEN.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8612c6dd",
   "metadata": {},
   "source": [
    "### Random Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c95983",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_ten = torch.rand(size=(4,2,3,1))\n",
    "print(random_ten)\n",
    "random_ten.ndim, random_ten.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30da1bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_ten = torch.ones((2,3,10))\n",
    "print(zero_ten)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc050b79",
   "metadata": {},
   "source": [
    "### arange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955d0387",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.arange(0,10))\n",
    "print(torch.arange(0,10,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3ca8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor([200,200,400],dtype=int,device=\"cpu\")\n",
    "torch.tensor([200,200,400],dtype=int,device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f888ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "int_32_tensor = torch.tensor([1,2,3,4,5], device='cpu' ,dtype=torch.int32)\n",
    "float_16_tensor = torch.tensor([3,1,2,3,3], dtype=torch.float16)\n",
    "\n",
    "(int_32_tensor * float_16_tensor).device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "036ae00a",
   "metadata": {},
   "source": [
    "### Tensor Manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cebbac81",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_tensor = torch.tensor([[1,2.3,2.1,3,10,0,1001,-2]], dtype=torch.int16, device=\"cpu\")\n",
    "mat_tensor_1 = torch.tensor([[1,2.3,2.34444], [22,1,300]], dtype=torch.float, device=\"cpu\")\n",
    "mat_tensor_2 = torch.tensor([[1,2,3], [1,1,3]], dtype=torch.float, device=\"cpu\")\n",
    "\n",
    "print(mat_tensor_1.T)\n",
    "print(f\"original tensor: \\n{mat_tensor_1}\\n\")\n",
    "print(f\"addition: \\n{mat_tensor_1 + 10.2}\\n\")\n",
    "print(f\"element-wise multiplication: \\n{mat_tensor_1 * 2}\\n\")\n",
    "print(f\"matrix multiplication (dot product): \\n{mat_tensor_1*mat_tensor_2}\\n\")\n",
    "print(f\"matrix multiplication (dot product): \\n{torch.matmul(mat_tensor_1,mat_tensor_1.T)}\\n\")\n",
    "print(f\"matrix multiplication (dot product): \\n{torch.mm(mat_tensor_1,mat_tensor_1.T)}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065480eb",
   "metadata": {},
   "source": [
    "### Tensor Aggregation (min, max, mean, sum and ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331342f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_tensor_1.dtype\n",
    "print(f\"some_tensor_1: \\n{mat_tensor_1}\\n\")\n",
    "print(f\"MIN: {mat_tensor_1.min()}\\n\")\n",
    "print(f\"MAX: {mat_tensor_1.max()}\\n\")\n",
    "print(f\"MEAN: {mat_tensor_1.mean()}\\n\")\n",
    "print(f\"ARGMIN: {mat_tensor_1.argmin()}\\n\")  # positional min\n",
    "print(f\"ARGMAX: {mat_tensor_1.argmax()}\\n\")  # positional max\n",
    "mat_tensor_1[1,2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eea04e2",
   "metadata": {},
   "source": [
    "### Reshaping, Stacking, Squeezing, Unsqueesing tensors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8765f198",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"vector: {vec_tensor}\", vec_tensor.shape,\"\\n\")\n",
    "reshaped_vec_tensor = vec_tensor.reshape(2,4)\n",
    "print(f\"Reshaped vec_tensor: \\n{reshaped_vec_tensor}\", reshaped_vec_tensor.shape, \"\\n\")\n",
    "\n",
    "reshaped_vec_tensor.view(4,2)  # view shares the same memory as reshaped_vec_tensor, lets say it is just a differet view of reshaped_vec_tensor.\n",
    "stacked_vec_tensor = torch.stack([vec_tensor, vec_tensor, vec_tensor], dim=0)  # vertical\n",
    "print(f\"stacked vec_tensor: \\n{stacked_vec_tensor}\", stacked_vec_tensor.shape, \"\\n\")\n",
    "\n",
    "stacked_vec_tensor = torch.stack([vec_tensor, vec_tensor, vec_tensor], dim=1)  # horizontal\n",
    "print(f\"stacked vec_tensor: \\n{stacked_vec_tensor}\", stacked_vec_tensor.shape, \"\\n\")\n",
    "\n",
    "squeezed_vec_tensor = vec_tensor.squeeze()  # removes all single dimensions from the target tensor\n",
    "print(f\"squeezed vec_tensor: \\n{squeezed_vec_tensor}\", squeezed_vec_tensor.shape, \"\\n\")\n",
    "\n",
    "unsqueezed_vec_tensor = squeezed_vec_tensor.unsqueeze(dim=0)  # adds a single dimension to the target tensor at a specific dim\n",
    "print(f\"unsqueezed vec_tensor: \\n{unsqueezed_vec_tensor}\", unsqueezed_vec_tensor.shape, \"\\n\")\n",
    "\n",
    "permuted_vec_tensor = reshaped_vec_tensor.permute(1,0)  # rearranges/swap the dimensions of a target tensor in a specified order (share same memory): second dim first, first dim come to second\n",
    "print(f\"permuted vec_tensor: \\n{permuted_vec_tensor}\", permuted_vec_tensor.shape, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fafedc6",
   "metadata": {},
   "source": [
    "### Indexing (similar to Numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94e1138",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_tensor_3 = torch.arange(10,19).reshape(1,3,3)\n",
    "print(f\"mat_tensor_3: \\n{mat_tensor_3}\", mat_tensor_3.shape)\n",
    "print(mat_tensor_3[0,2,2])\n",
    "print(mat_tensor_3[0,:,2])\n",
    "print(mat_tensor_3[0,2,:])\n",
    "print(mat_tensor_3[0][2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8957f267",
   "metadata": {},
   "source": [
    "### Pytorch Tensors and Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0750b1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_array = np.arange(1,10)\n",
    "torch_vec = torch.arange(1,10)\n",
    "print(np_array, \"\\n\", torch_vec)\n",
    "\n",
    "print()\n",
    "print(torch.from_numpy(np_array))  # convert numpy to tensor\n",
    "print(torch_vec.numpy())  # convert tensor to numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e188f45c",
   "metadata": {},
   "source": [
    "### Reproducibility; taking out of random\n",
    "In short, how a Neural Network(NN) learns:\n",
    "\n",
    "`Start with a random number` -> `tensor operations` -> `update random numbers trying to make them \n",
    "a better representation of the data` -> `again` -> `again` -> ...\n",
    "\n",
    "To reduce randomness in NN, PyTorch introduced a concept called **random seed** which `flavors` the randomness. (makes the randomness reproducible)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2ebcf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42\n",
    "\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "rand_tensor_A = torch.rand(1,2,4)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "rand_tensor_B = torch.rand(1,2,4)\n",
    "print(f\"rand_tensor_A: \\n{rand_tensor_A}\\n\")\n",
    "print(f\"rand_tensor_A: \\n{rand_tensor_B}\\n\")\n",
    "\n",
    "print(rand_tensor_A == rand_tensor_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1efde7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()\n",
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b8b746",
   "metadata": {},
   "source": [
    "## PyTorch Workflow\n",
    "\n",
    "Using linear regression formula to make a straight line with known parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4ae9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = 0.7\n",
    "bias = 0.3\n",
    "\n",
    "start  = 0\n",
    "end = 1 \n",
    "step = 0.02\n",
    "x = torch.arange(start, end, step).unsqueeze(dim=1)  # feature (input)\n",
    "y = weight * x + bias  # label (ouputs)\n",
    "\n",
    "x[:10], y[:10]  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1627ba89",
   "metadata": {},
   "source": [
    "#### Splitting data into training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281ac2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(x), len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca188085",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = int(0.8 * len(x))\n",
    "x_train, y_train = x[:train_set], y[:train_set]\n",
    "x_test, y_test = x[train_set:], y[train_set:]\n",
    "\n",
    "len(x_train), len(y_train), len(x_test), len(y_test)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf423d9",
   "metadata": {},
   "source": [
    "### Visualize, visualize, visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b90d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predictions(train_data=x_train, train_labels=y_train, test_data=x_test, test_labels=y_test, predictions=None):\n",
    "    \"\"\"\n",
    "    Plots training data, test data and compares predictions.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10,7))\n",
    "    plt.scatter(train_data, train_labels, c = \"b\", s = 4, label=\"Training data\")\n",
    "    plt.scatter(test_data, test_labels, c = \"g\", s = 4, label=\"Testing data\")\n",
    "    \n",
    "    if predictions is not None:\n",
    "        plt.scatter(test_data, predictions, c = \"r\", s = 4, label=\"Predictions\")\n",
    "    \n",
    "    plt.legend(prop={\"size\":14})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00f3142",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predictions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6c4fda",
   "metadata": {},
   "source": [
    "# Building our first PyTorch __model__\n",
    "\n",
    "Creating a linear regression model class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c018af",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegresssionModel(nn.Module):  # nn.Module is the base class for all neural network modules in PyTorch (containts all the build blocks for NN)\n",
    "    def __init__(self):  # constructor\n",
    "        super().__init__()\n",
    "        # Our model starts with random weights and bias:\n",
    "        self.weights = nn.Parameter(torch.randn(1, dtype=torch.float), requires_grad=True)\n",
    "        self.bias = nn.Parameter(torch.randn(1, dtype=torch.float), requires_grad=True)\n",
    "        \n",
    "    # Forward method to define the computation in the model.\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:  # x is input\n",
    "        return self.weights * x + self.bias  # Linear regression equation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12970cb",
   "metadata": {},
   "source": [
    "### PyTorch model building essentials:\n",
    "\n",
    "* __torch.nn__ -> Contains all of the buildings for computatinal graphs (NN)\n",
    "* __torch.nn.Parameter__ -> What parameters should our model try and learn\n",
    "* __torch.nn.Module__ -> The base class for all NN modules, if you subclass it you should overwrite forward()\n",
    "* __torch.optim__ -> this where the optimizer in PyTorch live, they will help with gradient descent\n",
    "* __def forward()__ -> All nn.Module subclasses require you to overwrite forward(), this method defines what happens in the forward computation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "941dc410",
   "metadata": {},
   "source": [
    "### Checking the contents of our PyTorch model:\n",
    "\n",
    "Using `.parameters()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "5af9827c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([0.3367], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.1288], requires_grad=True)]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)  # set the random seed for reproducibility\n",
    "model_0 = LinearRegresssionModel()\n",
    "list(model_0.parameters())  # Check out the parameters in our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df500769",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_0.state_dict()  # list named parameters with their values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312e65a1",
   "metadata": {},
   "source": [
    "### Making predictions using `torch.inference_mode()` (Validation / Test)\n",
    "\n",
    "How well the model predicts `y_test` from `x_test`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4899a674",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions with model (good practice to make predictions under inference mode):\n",
    "with torch.inference_mode():  # No graph building (NN), no gradient tracking, no .backward(), intended for inference only.\n",
    "    y_pred = model_0(x_test)  # forward pass\n",
    "    # print(\"inference mode:\")\n",
    "\n",
    "y_pred\n",
    "\n",
    "# with torch.no_grad():  # another way to turn off gradients, however inference_mode is prefered (faster)\n",
    "#     y_pred = model_0(x_test)\n",
    "#     print(\"no grad:\")\n",
    "#     print(y_pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f99fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predictions(predictions=y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3383cd16",
   "metadata": {},
   "source": [
    "The whole idea of trainig is for a model to move from some uknown parameters (most often random) to some known parameters.\n",
    "\n",
    "#### Solution:\n",
    "\n",
    "__Loss function__: One way to measure how poor or how wrong our model predicts vs. the ideal outputs, is loss funtion / cost function / criterion\n",
    "\n",
    "__Optimizer__: Takes into account the loss of a model and adjusts the model's parameters (e.g. weights and bias) to improve the loss function.\n",
    "\n",
    "* __params__: the model parameters you'd like to optimize, i.e. params=model_0.parameters()\n",
    "* __lr__ (learning rate): a hyperparameter that defines how big/small the optimizer changes the parameters with each step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226253b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(model_0.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa0f358",
   "metadata": {},
   "source": [
    "### Setting up a __Loss Function__ and __Optimizer__:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "0ae27546",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Creating instances of loss function and optimizer:\n",
    "\n",
    "loss_fun = nn.L1Loss()  # mean absolute error (MAE)\n",
    "optimizer = torch.optim.SGD(params=model_0.parameters(), lr=0.01)  # Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abcd664a",
   "metadata": {},
   "source": [
    "# Building a __training__ & __testing__ loop in PyTorch:\n",
    "1) __Loop__ through the data\n",
    "2) __Forward pass__ -> data moving through the model (NN)\n",
    "3) __Loss calculation__ -> Comparing the forward pass to ground truth labels\n",
    "4) __Optimizer__\n",
    "5) __Loss backward__ -> backpropagation\n",
    "6) __Optimizer step__ -> gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b471fced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true weight: 0.7, bias: 0.3 \n",
      "\n",
      "Epoch: 0 | Loss: 1.19724 | Weight: -1.123 | Bias: -0.186 | Test loss: 2.109\n",
      "Epoch: 1 | Loss: 1.19724 | Weight: -1.123 | Bias: -0.186 | Test loss: 2.109\n",
      "Epoch: 2 | Loss: 1.19724 | Weight: -1.123 | Bias: -0.186 | Test loss: 2.109\n",
      "Epoch: 3 | Loss: 1.19724 | Weight: -1.123 | Bias: -0.186 | Test loss: 2.109\n",
      "Epoch: 4 | Loss: 1.19724 | Weight: -1.123 | Bias: -0.186 | Test loss: 2.109\n",
      "Epoch: 5 | Loss: 1.19724 | Weight: -1.123 | Bias: -0.186 | Test loss: 2.109\n",
      "Epoch: 6 | Loss: 1.19724 | Weight: -1.123 | Bias: -0.186 | Test loss: 2.109\n",
      "Epoch: 7 | Loss: 1.19724 | Weight: -1.123 | Bias: -0.186 | Test loss: 2.109\n",
      "Epoch: 8 | Loss: 1.19724 | Weight: -1.123 | Bias: -0.186 | Test loss: 2.109\n",
      "Epoch: 9 | Loss: 1.19724 | Weight: -1.123 | Bias: -0.186 | Test loss: 2.109\n",
      "Epoch: 10 | Loss: 1.19724 | Weight: -1.123 | Bias: -0.186 | Test loss: 2.109\n",
      "Epoch: 11 | Loss: 1.19724 | Weight: -1.123 | Bias: -0.186 | Test loss: 2.109\n",
      "Epoch: 12 | Loss: 1.19724 | Weight: -1.123 | Bias: -0.186 | Test loss: 2.109\n",
      "Epoch: 13 | Loss: 1.19724 | Weight: -1.123 | Bias: -0.186 | Test loss: 2.109\n",
      "Epoch: 14 | Loss: 1.19724 | Weight: -1.123 | Bias: -0.186 | Test loss: 2.109\n",
      "Epoch: 15 | Loss: 1.19724 | Weight: -1.123 | Bias: -0.186 | Test loss: 2.109\n",
      "Epoch: 16 | Loss: 1.19724 | Weight: -1.123 | Bias: -0.186 | Test loss: 2.109\n",
      "Epoch: 17 | Loss: 1.19724 | Weight: -1.123 | Bias: -0.186 | Test loss: 2.109\n",
      "Epoch: 18 | Loss: 1.19724 | Weight: -1.123 | Bias: -0.186 | Test loss: 2.109\n",
      "Epoch: 19 | Loss: 1.19724 | Weight: -1.123 | Bias: -0.186 | Test loss: 2.109\n",
      "Epoch: 20 | Loss: 1.19724 | Weight: -1.123 | Bias: -0.186 | Test loss: 2.109\n",
      "Epoch: 21 | Loss: 1.19724 | Weight: -1.123 | Bias: -0.186 | Test loss: 2.109\n",
      "Epoch: 22 | Loss: 1.19724 | Weight: -1.123 | Bias: -0.186 | Test loss: 2.109\n",
      "Epoch: 23 | Loss: 1.19724 | Weight: -1.123 | Bias: -0.186 | Test loss: 2.109\n",
      "Epoch: 24 | Loss: 1.19724 | Weight: -1.123 | Bias: -0.186 | Test loss: 2.109\n",
      "Epoch: 25 | Loss: 1.19724 | Weight: -1.123 | Bias: -0.186 | Test loss: 2.109\n",
      "Epoch: 26 | Loss: 1.19724 | Weight: -1.123 | Bias: -0.186 | Test loss: 2.109\n",
      "Epoch: 27 | Loss: 1.19724 | Weight: -1.123 | Bias: -0.186 | Test loss: 2.109\n",
      "Epoch: 28 | Loss: 1.19724 | Weight: -1.123 | Bias: -0.186 | Test loss: 2.109\n",
      "Epoch: 29 | Loss: 1.19724 | Weight: -1.123 | Bias: -0.186 | Test loss: 2.109\n",
      "Epoch: 30 | Loss: 1.19724 | Weight: -1.123 | Bias: -0.186 | Test loss: 2.109\n",
      "Epoch: 31 | Loss: 1.19724 | Weight: -1.123 | Bias: -0.186 | Test loss: 2.109\n",
      "Epoch: 32 | Loss: 1.19724 | Weight: -1.123 | Bias: -0.186 | Test loss: 2.109\n",
      "Epoch: 33 | Loss: 1.19724 | Weight: -1.123 | Bias: -0.186 | Test loss: 2.109\n",
      "Epoch: 34 | Loss: 1.19724 | Weight: -1.123 | Bias: -0.186 | Test loss: 2.109\n",
      "Epoch: 35 | Loss: 1.19724 | Weight: -1.123 | Bias: -0.186 | Test loss: 2.109\n",
      "Epoch: 36 | Loss: 1.19724 | Weight: -1.123 | Bias: -0.186 | Test loss: 2.109\n",
      "Epoch: 37 | Loss: 1.19724 | Weight: -1.123 | Bias: -0.186 | Test loss: 2.109\n",
      "Epoch: 38 | Loss: 1.19724 | Weight: -1.123 | Bias: -0.186 | Test loss: 2.109\n",
      "Epoch: 39 | Loss: 1.19724 | Weight: -1.123 | Bias: -0.186 | Test loss: 2.109\n",
      "Epoch: 40 | Loss: 1.19724 | Weight: -1.123 | Bias: -0.186 | Test loss: 2.109\n",
      "Epoch: 41 | Loss: 1.19724 | Weight: -1.123 | Bias: -0.186 | Test loss: 2.109\n",
      "Epoch: 42 | Loss: 1.19724 | Weight: -1.123 | Bias: -0.186 | Test loss: 2.109\n",
      "Epoch: 43 | Loss: 1.19724 | Weight: -1.123 | Bias: -0.186 | Test loss: 2.109\n",
      "Epoch: 44 | Loss: 1.19724 | Weight: -1.123 | Bias: -0.186 | Test loss: 2.109\n",
      "Epoch: 45 | Loss: 1.19724 | Weight: -1.123 | Bias: -0.186 | Test loss: 2.109\n",
      "Epoch: 46 | Loss: 1.19724 | Weight: -1.123 | Bias: -0.186 | Test loss: 2.109\n",
      "Epoch: 47 | Loss: 1.19724 | Weight: -1.123 | Bias: -0.186 | Test loss: 2.109\n",
      "Epoch: 48 | Loss: 1.19724 | Weight: -1.123 | Bias: -0.186 | Test loss: 2.109\n",
      "Epoch: 49 | Loss: 1.19724 | Weight: -1.123 | Bias: -0.186 | Test loss: 2.109\n",
      "Epoch: 50 | Loss: 1.19724 | Weight: -1.123 | Bias: -0.186 | Test loss: 2.109\n",
      "Epoch: 51 | Loss: 1.19724 | Weight: -1.123 | Bias: -0.186 | Test loss: 2.109\n",
      "Epoch: 52 | Loss: 1.19724 | Weight: -1.123 | Bias: -0.186 | Test loss: 2.109\n",
      "Epoch: 53 | Loss: 1.19724 | Weight: -1.123 | Bias: -0.186 | Test loss: 2.109\n",
      "Epoch: 54 | Loss: 1.19724 | Weight: -1.123 | Bias: -0.186 | Test loss: 2.109\n",
      "Epoch: 55 | Loss: 1.19724 | Weight: -1.123 | Bias: -0.186 | Test loss: 2.109\n",
      "Epoch: 56 | Loss: 1.19724 | Weight: -1.123 | Bias: -0.186 | Test loss: 2.109\n",
      "Epoch: 57 | Loss: 1.19724 | Weight: -1.123 | Bias: -0.186 | Test loss: 2.109\n",
      "Epoch: 58 | Loss: 1.19724 | Weight: -1.123 | Bias: -0.186 | Test loss: 2.109\n",
      "Epoch: 59 | Loss: 1.19724 | Weight: -1.123 | Bias: -0.186 | Test loss: 2.109\n",
      "Epoch: 60 | Loss: 1.19724 | Weight: -1.123 | Bias: -0.186 | Test loss: 2.109\n",
      "Epoch: 61 | Loss: 1.19724 | Weight: -1.123 | Bias: -0.186 | Test loss: 2.109\n",
      "Epoch: 62 | Loss: 1.19724 | Weight: -1.123 | Bias: -0.186 | Test loss: 2.109\n",
      "Epoch: 63 | Loss: 1.19724 | Weight: -1.123 | Bias: -0.186 | Test loss: 2.109\n",
      "Epoch: 64 | Loss: 1.19724 | Weight: -1.123 | Bias: -0.186 | Test loss: 2.109\n",
      "Epoch: 65 | Loss: 1.19724 | Weight: -1.123 | Bias: -0.186 | Test loss: 2.109\n",
      "Epoch: 66 | Loss: 1.19724 | Weight: -1.123 | Bias: -0.186 | Test loss: 2.109\n",
      "Epoch: 67 | Loss: 1.19724 | Weight: -1.123 | Bias: -0.186 | Test loss: 2.109\n",
      "Epoch: 68 | Loss: 1.19724 | Weight: -1.123 | Bias: -0.186 | Test loss: 2.109\n",
      "Epoch: 69 | Loss: 1.19724 | Weight: -1.123 | Bias: -0.186 | Test loss: 2.109\n",
      "Epoch: 70 | Loss: 1.19724 | Weight: -1.123 | Bias: -0.186 | Test loss: 2.109\n",
      "Epoch: 71 | Loss: 1.19724 | Weight: -1.123 | Bias: -0.186 | Test loss: 2.109\n",
      "Epoch: 72 | Loss: 1.19724 | Weight: -1.123 | Bias: -0.186 | Test loss: 2.109\n",
      "Epoch: 73 | Loss: 1.19724 | Weight: -1.123 | Bias: -0.186 | Test loss: 2.109\n",
      "Epoch: 74 | Loss: 1.19724 | Weight: -1.123 | Bias: -0.186 | Test loss: 2.109\n",
      "Epoch: 75 | Loss: 1.19724 | Weight: -1.123 | Bias: -0.186 | Test loss: 2.109\n",
      "Epoch: 76 | Loss: 1.19724 | Weight: -1.123 | Bias: -0.186 | Test loss: 2.109\n",
      "Epoch: 77 | Loss: 1.19724 | Weight: -1.123 | Bias: -0.186 | Test loss: 2.109\n",
      "Epoch: 78 | Loss: 1.19724 | Weight: -1.123 | Bias: -0.186 | Test loss: 2.109\n",
      "Epoch: 79 | Loss: 1.19724 | Weight: -1.123 | Bias: -0.186 | Test loss: 2.109\n",
      "Epoch: 80 | Loss: 1.19724 | Weight: -1.123 | Bias: -0.186 | Test loss: 2.109\n",
      "Epoch: 81 | Loss: 1.19724 | Weight: -1.123 | Bias: -0.186 | Test loss: 2.109\n",
      "Epoch: 82 | Loss: 1.19724 | Weight: -1.123 | Bias: -0.186 | Test loss: 2.109\n",
      "Epoch: 83 | Loss: 1.19724 | Weight: -1.123 | Bias: -0.186 | Test loss: 2.109\n",
      "Epoch: 84 | Loss: 1.19724 | Weight: -1.123 | Bias: -0.186 | Test loss: 2.109\n",
      "Epoch: 85 | Loss: 1.19724 | Weight: -1.123 | Bias: -0.186 | Test loss: 2.109\n",
      "Epoch: 86 | Loss: 1.19724 | Weight: -1.123 | Bias: -0.186 | Test loss: 2.109\n",
      "Epoch: 87 | Loss: 1.19724 | Weight: -1.123 | Bias: -0.186 | Test loss: 2.109\n",
      "Epoch: 88 | Loss: 1.19724 | Weight: -1.123 | Bias: -0.186 | Test loss: 2.109\n",
      "Epoch: 89 | Loss: 1.19724 | Weight: -1.123 | Bias: -0.186 | Test loss: 2.109\n",
      "Epoch: 90 | Loss: 1.19724 | Weight: -1.123 | Bias: -0.186 | Test loss: 2.109\n",
      "Epoch: 91 | Loss: 1.19724 | Weight: -1.123 | Bias: -0.186 | Test loss: 2.109\n",
      "Epoch: 92 | Loss: 1.19724 | Weight: -1.123 | Bias: -0.186 | Test loss: 2.109\n",
      "Epoch: 93 | Loss: 1.19724 | Weight: -1.123 | Bias: -0.186 | Test loss: 2.109\n",
      "Epoch: 94 | Loss: 1.19724 | Weight: -1.123 | Bias: -0.186 | Test loss: 2.109\n",
      "Epoch: 95 | Loss: 1.19724 | Weight: -1.123 | Bias: -0.186 | Test loss: 2.109\n",
      "Epoch: 96 | Loss: 1.19724 | Weight: -1.123 | Bias: -0.186 | Test loss: 2.109\n",
      "Epoch: 97 | Loss: 1.19724 | Weight: -1.123 | Bias: -0.186 | Test loss: 2.109\n",
      "Epoch: 98 | Loss: 1.19724 | Weight: -1.123 | Bias: -0.186 | Test loss: 2.109\n",
      "Epoch: 99 | Loss: 1.19724 | Weight: -1.123 | Bias: -0.186 | Test loss: 2.109\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OrderedDict([('weights', tensor([-1.1229])), ('bias', tensor([-0.1863]))])"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "# model_0 = LinearRegresssionModel()  # create a new instance of the model to reset the parameters\n",
    "\n",
    "epochs = 100  # TODO; Another hyperparameter that is one loop through the data.\n",
    "\n",
    "# Track different values:\n",
    "epoch_count = []\n",
    "loss_values = []\n",
    "test_loss_values = []\n",
    "\n",
    "print(f\"true weight: {weight}, bias: {bias} \\n\")\n",
    "### Training Loop ###\n",
    "for epoch in range (epochs):\n",
    "    model_0.train()  # (GOOD PRACTICE) set the model to training mode (model remember the parameters it has), sets all the parameters that require gradients to require gradients\n",
    "    \n",
    "    y_pred = model_0(x_train)  # forward pass (\"forward propagation\")\n",
    "    loss = loss_fun(y_pred, y_train)  # compute the \"loss\" (predictions vs. labels)\n",
    "    optimizer.zero_grad()  # zero grad \"optimizer\" (set the gradients to zero)\n",
    "    loss.backward()  # \"backpropagation\" (compute the gradients of each parameter with respect to the loss)\n",
    "    optimizer.step()  # update model parameters (weights) via \"gradient descent\"\n",
    "\n",
    "    ### Testing/Evaluating Loop ###\n",
    "    model_0.eval()  # (GOOD PRACTICE) Turns off different setting s in the model not needed for evaluation/test(turns off \"dropout\" and \"batch norm\" (if any))\n",
    "    with torch.inference_mode():  # turn off gradient tracking and a couple of more things behind the scens for inference/testing\n",
    "        test_pred_new = model_0(x_test) # forward pass: just using the trained model to make predictions\n",
    "        test_loss = loss_fun(test_pred_new, y_test)  # compute the loss\n",
    "        # print(f\"Test loss: {test_loss:.5f}\")\n",
    "\n",
    "    # if epoch % 2 == 0:  # print every 2 epochs\n",
    "    epoch_count.append(epoch)\n",
    "    loss_values.append(loss.detach().numpy())\n",
    "    test_loss_values.append(test_loss.detach().numpy())\n",
    "    \n",
    "    print(f\"Epoch: {epoch} | Loss: {loss:.5f} | Weight: {model_0.weights.item():.3f} | Bias: {model_0.bias.item():.3f} | Test loss: {test_loss:.3f}\" )\n",
    "\n",
    "model_0.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "3640c8b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot_predictions(predictions=y_pred)\n",
    "plot_predictions(predictions=test_pred_new)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

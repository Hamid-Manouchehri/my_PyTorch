{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d147a727",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f184a798",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn # All the building blocks for neural networks\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55702d06",
   "metadata": {},
   "source": [
    "### Setup device-agnostic code (running the code on any available accelerator):\n",
    "\n",
    "PyTorch is capable of running on both GPU or CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b30448",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch.cuda.device_count()\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893c51e0",
   "metadata": {},
   "source": [
    "### Scalar & Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfff794a",
   "metadata": {},
   "outputs": [],
   "source": [
    "scalar = torch.tensor(5)\n",
    "scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b7ad77",
   "metadata": {},
   "outputs": [],
   "source": [
    "scalar.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9e31d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = torch.tensor([1,3])\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2c7e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9175b51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13510354",
   "metadata": {},
   "source": [
    "### Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6404d07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAT = torch.tensor([[1, 2],[3, 3], [3,4]])\n",
    "MAT.ndim\n",
    "MAT.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6784813",
   "metadata": {},
   "source": [
    "### Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8631a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEN = torch.tensor([[[1,2,3],\n",
    "                     [2,3,3],\n",
    "                     [1,1,1],\n",
    "                     [10,10,10]],\n",
    "                    [[2,2,2],\n",
    "                     [1,1,1],\n",
    "                     [10.,11,11],\n",
    "                     [13,13,13]]])\n",
    "TEN.ndim\n",
    "TEN.size\n",
    "TEN.shape\n",
    "TEN.dim\n",
    "TEN.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8612c6dd",
   "metadata": {},
   "source": [
    "### Random Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c95983",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_ten = torch.rand(size=(4,2,3,1))\n",
    "print(random_ten)\n",
    "random_ten.ndim, random_ten.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30da1bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_ten = torch.ones((2,3,10))\n",
    "print(zero_ten)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc050b79",
   "metadata": {},
   "source": [
    "### arange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955d0387",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.arange(0,10))\n",
    "print(torch.arange(0,10,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3ca8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor([200,200,400],dtype=int,device=\"cpu\")\n",
    "torch.tensor([200,200,400],dtype=int,device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f888ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "int_32_tensor = torch.tensor([1,2,3,4,5], device='cpu' ,dtype=torch.int32)\n",
    "float_16_tensor = torch.tensor([3,1,2,3,3], dtype=torch.float16)\n",
    "\n",
    "(int_32_tensor * float_16_tensor).device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "036ae00a",
   "metadata": {},
   "source": [
    "### Tensor Manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cebbac81",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_tensor = torch.tensor([[1,2.3,2.1,3,10,0,1001,-2]], dtype=torch.int16, device=\"cpu\")\n",
    "mat_tensor_1 = torch.tensor([[1,2.3,2.34444], [22,1,300]], dtype=torch.float, device=\"cpu\")\n",
    "mat_tensor_2 = torch.tensor([[1,2,3], [1,1,3]], dtype=torch.float, device=\"cpu\")\n",
    "\n",
    "print(mat_tensor_1.T)\n",
    "print(f\"original tensor: \\n{mat_tensor_1}\\n\")\n",
    "print(f\"addition: \\n{mat_tensor_1 + 10.2}\\n\")\n",
    "print(f\"element-wise multiplication: \\n{mat_tensor_1 * 2}\\n\")\n",
    "print(f\"matrix multiplication (dot product): \\n{mat_tensor_1*mat_tensor_2}\\n\")\n",
    "print(f\"matrix multiplication (dot product): \\n{torch.matmul(mat_tensor_1,mat_tensor_1.T)}\\n\")\n",
    "print(f\"matrix multiplication (dot product): \\n{torch.mm(mat_tensor_1,mat_tensor_1.T)}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065480eb",
   "metadata": {},
   "source": [
    "### Tensor Aggregation (min, max, mean, sum and ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331342f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_tensor_1.dtype\n",
    "print(f\"some_tensor_1: \\n{mat_tensor_1}\\n\")\n",
    "print(f\"MIN: {mat_tensor_1.min()}\\n\")\n",
    "print(f\"MAX: {mat_tensor_1.max()}\\n\")\n",
    "print(f\"MEAN: {mat_tensor_1.mean()}\\n\")\n",
    "print(f\"ARGMIN: {mat_tensor_1.argmin()}\\n\")  # positional min\n",
    "print(f\"ARGMAX: {mat_tensor_1.argmax()}\\n\")  # positional max\n",
    "mat_tensor_1[1,2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eea04e2",
   "metadata": {},
   "source": [
    "### Reshaping, Stacking, Squeezing, Unsqueesing tensors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8765f198",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"vector: {vec_tensor}\", vec_tensor.shape,\"\\n\")\n",
    "reshaped_vec_tensor = vec_tensor.reshape(2,4)\n",
    "print(f\"Reshaped vec_tensor: \\n{reshaped_vec_tensor}\", reshaped_vec_tensor.shape, \"\\n\")\n",
    "\n",
    "reshaped_vec_tensor.view(4,2)  # view shares the same memory as reshaped_vec_tensor, lets say it is just a differet view of reshaped_vec_tensor.\n",
    "stacked_vec_tensor = torch.stack([vec_tensor, vec_tensor, vec_tensor], dim=0)  # vertical\n",
    "print(f\"stacked vec_tensor: \\n{stacked_vec_tensor}\", stacked_vec_tensor.shape, \"\\n\")\n",
    "\n",
    "stacked_vec_tensor = torch.stack([vec_tensor, vec_tensor, vec_tensor], dim=1)  # horizontal\n",
    "print(f\"stacked vec_tensor: \\n{stacked_vec_tensor}\", stacked_vec_tensor.shape, \"\\n\")\n",
    "\n",
    "squeezed_vec_tensor = vec_tensor.squeeze()  # removes all single dimensions from the target tensor\n",
    "print(f\"squeezed vec_tensor: \\n{squeezed_vec_tensor}\", squeezed_vec_tensor.shape, \"\\n\")\n",
    "\n",
    "unsqueezed_vec_tensor = squeezed_vec_tensor.unsqueeze(dim=0)  # adds a single dimension to the target tensor at a specific dim\n",
    "print(f\"unsqueezed vec_tensor: \\n{unsqueezed_vec_tensor}\", unsqueezed_vec_tensor.shape, \"\\n\")\n",
    "\n",
    "permuted_vec_tensor = reshaped_vec_tensor.permute(1,0)  # rearranges/swap the dimensions of a target tensor in a specified order (share same memory): second dim first, first dim come to second\n",
    "print(f\"permuted vec_tensor: \\n{permuted_vec_tensor}\", permuted_vec_tensor.shape, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fafedc6",
   "metadata": {},
   "source": [
    "### Indexing (similar to Numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94e1138",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_tensor_3 = torch.arange(10,19).reshape(1,3,3)\n",
    "print(f\"mat_tensor_3: \\n{mat_tensor_3}\", mat_tensor_3.shape)\n",
    "print(mat_tensor_3[0,2,2])\n",
    "print(mat_tensor_3[0,:,2])\n",
    "print(mat_tensor_3[0,2,:])\n",
    "print(mat_tensor_3[0][2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8957f267",
   "metadata": {},
   "source": [
    "### Pytorch Tensors and Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0750b1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_array = np.arange(1,10)\n",
    "torch_vec = torch.arange(1,10)\n",
    "print(np_array, \"\\n\", torch_vec)\n",
    "\n",
    "print()\n",
    "print(torch.from_numpy(np_array))  # convert numpy to tensor\n",
    "print(torch_vec.numpy())  # convert tensor to numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e188f45c",
   "metadata": {},
   "source": [
    "### Reproducibility; taking out of random\n",
    "In short, how a Neural Network(NN) learns:\n",
    "\n",
    "`Start with a random number` -> `tensor operations` -> `update random numbers trying to make them \n",
    "a better representation of the data` -> `again` -> `again` -> ...\n",
    "\n",
    "To reduce randomness in NN, PyTorch introduced a concept called **random seed** which `flavors` the randomness. (makes the randomness reproducible)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2ebcf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42\n",
    "\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "rand_tensor_A = torch.rand(1,2,4)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "rand_tensor_B = torch.rand(1,2,4)\n",
    "print(f\"rand_tensor_A: \\n{rand_tensor_A}\\n\")\n",
    "print(f\"rand_tensor_A: \\n{rand_tensor_B}\\n\")\n",
    "\n",
    "print(rand_tensor_A == rand_tensor_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1efde7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()\n",
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b8b746",
   "metadata": {},
   "source": [
    "## PyTorch Workflow\n",
    "\n",
    "Using linear regression formula to make a straight line with known parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4ae9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = 0.7\n",
    "bias = 0.3\n",
    "\n",
    "start  = 0\n",
    "end = 1 \n",
    "step = 0.02\n",
    "x = torch.arange(start, end, step).unsqueeze(dim=1)  # feature (input)\n",
    "y = weight * x + bias  # label (ouputs)\n",
    "\n",
    "x[:10], y[:10]  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1627ba89",
   "metadata": {},
   "source": [
    "#### Splitting data into training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281ac2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(x), len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca188085",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = int(0.8 * len(x))\n",
    "x_train, y_train = x[:train_set], y[:train_set]\n",
    "x_test, y_test = x[train_set:], y[train_set:]\n",
    "\n",
    "len(x_train), len(y_train), len(x_test), len(y_test)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf423d9",
   "metadata": {},
   "source": [
    "### Visualize, visualize, visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b90d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predictions(train_data=x_train, train_labels=y_train, test_data=x_test, test_labels=y_test, predictions=None):\n",
    "    \"\"\"\n",
    "    Plots training data, test data and compares predictions.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10,7))\n",
    "    plt.scatter(train_data, train_labels, c = \"b\", s = 4, label=\"Training data\")\n",
    "    plt.scatter(test_data, test_labels, c = \"g\", s = 4, label=\"Testing data\")\n",
    "    \n",
    "    if predictions is not None:\n",
    "        plt.scatter(test_data, predictions, c = \"r\", s = 4, label=\"Predictions\")\n",
    "    \n",
    "    plt.legend(prop={\"size\":14})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00f3142",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predictions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6c4fda",
   "metadata": {},
   "source": [
    "# Building our first PyTorch __model__\n",
    "\n",
    "Creating a linear regression model class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c018af",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegresssionModel(nn.Module):  # nn.Module is the base class for all neural network modules in PyTorch (containts all the build blocks for NN)\n",
    "    def __init__(self):  # constructor\n",
    "        super().__init__()\n",
    "        # Our model starts with random weights and bias:\n",
    "        self.weights = nn.Parameter(torch.randn(1, dtype=torch.float), requires_grad=True)\n",
    "        self.bias = nn.Parameter(torch.randn(1, dtype=torch.float), requires_grad=True)\n",
    "        \n",
    "    # Forward method to define the computation in the model.\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:  # x is input\n",
    "        return self.weights * x + self.bias  # Linear regression equation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12970cb",
   "metadata": {},
   "source": [
    "### PyTorch model building essentials:\n",
    "\n",
    "* __torch.nn__ -> Contains all of the buildings for computatinal graphs (NN)\n",
    "* __torch.nn.Parameter__ -> What parameters should our model try and learn\n",
    "* __torch.nn.Module__ -> The base class for all NN modules, if you subclass it you should overwrite forward()\n",
    "* __torch.optim__ -> this where the optimizer in PyTorch live, they will help with gradient descent\n",
    "* __def forward()__ -> All nn.Module subclasses require you to overwrite forward(), this method defines what happens in the forward computation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "941dc410",
   "metadata": {},
   "source": [
    "### Checking the contents of our PyTorch model:\n",
    "\n",
    "Using `.parameters()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af9827c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)  # set the random seed for reproducibility\n",
    "model_0 = LinearRegresssionModel()\n",
    "list(model_0.parameters())  # Check out the parameters in our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df500769",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_0.state_dict()  # list named parameters with their values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312e65a1",
   "metadata": {},
   "source": [
    "### Making predictions using `torch.inference_mode()` (Validation / Test)\n",
    "\n",
    "How well the model predicts `y_test` from `x_test`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4899a674",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions with model (good practice to make predictions under inference mode):\n",
    "with torch.inference_mode():  # No graph building (NN), no gradient tracking, no .backward(), intended for inference only.\n",
    "    y_pred = model_0(x_test)  # forward pass\n",
    "    # print(\"inference mode:\")\n",
    "\n",
    "y_pred\n",
    "\n",
    "# with torch.no_grad():  # another way to turn off gradients, however inference_mode is prefered (faster)\n",
    "#     y_pred = model_0(x_test)\n",
    "#     print(\"no grad:\")\n",
    "#     print(y_pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f99fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predictions(predictions=y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3383cd16",
   "metadata": {},
   "source": [
    "The whole idea of trainig is for a model to move from some uknown parameters (most often random) to some known parameters.\n",
    "\n",
    "#### Solution:\n",
    "\n",
    "__Loss function__: One way to measure how poor or how wrong our model predicts vs. the ideal outputs, is loss funtion / cost function / criterion\n",
    "\n",
    "__Optimizer__: Takes into account the loss of a model and adjusts the model's parameters (e.g. weights and bias) to improve the loss function.\n",
    "\n",
    "* __params__: the model parameters you'd like to optimize, i.e. params=model_0.parameters()\n",
    "* __lr__ (learning rate): a hyperparameter that defines how big/small the optimizer changes the parameters with each step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226253b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(model_0.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa0f358",
   "metadata": {},
   "source": [
    "### Setting up a __Loss Function__ and __Optimizer__:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae27546",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fun = nn.L1Loss()  # mean absolute error (MAE)\n",
    "optimizer = torch.optim.SGD(params=model_0.parameters(), lr=0.01)  # Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abcd664a",
   "metadata": {},
   "source": [
    "# Building a __training__ & __testing__ loop in PyTorch:\n",
    "1) __Loop__ through the data\n",
    "2) __Forward pass__ -> data moving through the model (NN)\n",
    "3) __Loss calculation__ -> Comparing the forward pass to ground truth labels\n",
    "4) __Optimizer__\n",
    "5) __Loss backward__ -> backpropagation\n",
    "6) __Optimizer step__ -> gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b471fced",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "epochs = 1000  # Another hyperparameter that is one loop through the data.\n",
    "\n",
    "### Training Loop ###\n",
    "for epoch in range (epochs):\n",
    "    model_0.train()  # (Good practice) set the model to training mode, sets all the parameters that require gradients to require gradients\n",
    "    \n",
    "    y_pred = model_0(x_train)  # forward pass (\"forward propagation\")\n",
    "    loss = loss_fun(y_pred, y_train)  # compute the \"loss\" (predictions vs. labels)\n",
    "    optimizer.zero_grad()  # zero grad \"optimizer\" (set the gradients to zero)\n",
    "    loss.backward()  # \"backpropagation\" (compute the gradients of each parameter with respect to the loss)\n",
    "    optimizer.step()  # update model parameters (weights) via \"gradient descent\"\n",
    "    \n",
    "    # if epoch % 2 == 0:  # print every 2 epochs\n",
    "    print(f\"Epoch: {epoch} | Loss: {loss:.5f} | Weight: {model_0.weights.item():.3f} | Bias: {model_0.bias.item():.3f}\" )\n",
    "\n",
    "    ### Testing Loop ###\n",
    "    model_0.eval()  # (Good practice) Turns off different setting s in the model not needed for evaluation/test(turns off \"dropout\" and \"batch norm\" (if any))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aed74e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.inference_mode():  # turn off gradient tracking and a couple of more things behind the scens for inference/testing\n",
    "    test_pred_new = model_0(x_test) # forward pass: just using the trained model to make predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3640c8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_0.state_dict()\n",
    "weight, bias\n",
    "# y_pred\n",
    "# plot_predictions(predictions=y_pred)\n",
    "plot_predictions(predictions=test_pred_new)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
